# üéØ R√©sum√© - Projet NLP : Analyse de Sentiment Multi-dimensionnelle

## üìå Vue d'Ensemble

**Objectif** : Cr√©er un syst√®me d'analyse de sentiment avanc√© qui d√©tecte non seulement le positif/n√©gatif, mais aussi les √©motions fines (joie, col√®re, peur, etc.) et l'ironie dans des textes fran√ßais (tweets, commentaires).

**Cat√©gorie** : Machine Learning Avanc√© & Deep Learning

---

## üõ†Ô∏è Technologies Principales

- **CamemBERT** : Mod√®le BERT sp√©cialis√© pour le fran√ßais
- **HuggingFace Transformers** : Framework pour les mod√®les
- **PyTorch** : Framework deep learning
- **Python 3.8+**

---

## üìÅ Structure du Projet

```
projet-nlp/
‚îú‚îÄ‚îÄ data/                  # Donn√©es brutes et trait√©es
‚îú‚îÄ‚îÄ notebooks/             # Exploration et exp√©rimentations
‚îú‚îÄ‚îÄ src/                   # Code source
‚îÇ   ‚îú‚îÄ‚îÄ data/             # Chargement et preprocessing
‚îÇ   ‚îú‚îÄ‚îÄ models/           # Mod√®les (CamemBERT multi-t√¢ches)
‚îÇ   ‚îú‚îÄ‚îÄ training/         # Entra√Ænement
‚îÇ   ‚îî‚îÄ‚îÄ evaluation/       # M√©triques et analyse
‚îú‚îÄ‚îÄ models/               # Mod√®les sauvegard√©s
‚îî‚îÄ‚îÄ results/              # R√©sultats et visualisations
```

---

## üéØ Les 3 T√¢ches √† R√©soudre

### 1. Classification d'√âmotions (7 classes)
- Joie, Tristesse, Col√®re, Peur, Surprise, D√©go√ªt, Neutre

### 2. Analyse de Sentiment (3 classes)
- Positif, N√©gatif, Neutre

### 3. D√©tection d'Ironie (2 classes)
- Ironique, Non-ironique

---

## üìä M√©thodologie en 5 Phases

### **Phase 1 : Donn√©es**
1. Collecter des datasets fran√ßais (DEFT, Allocine, GoEmotions traduit)
2. Nettoyer les textes (URLs, mentions) **MAIS garder emojis et ponctuation !**
3. S√©parer : 70% train / 15% validation / 15% test

**Key point** : Stratifier le split pour garder la distribution des classes

### **Phase 2 : Exploration**
1. Statistiques descriptives (longueur des textes, distribution des classes)
2. Visualisations (word clouds, distributions)
3. Identifier les d√©s√©quilibres de classes

### **Phase 3 : Baseline**
1. TF-IDF + Logistic Regression
2. √âtablir la performance minimum √† battre
3. F1-Score attendu : ~0.50-0.60

**Pourquoi ?** Pour prouver que le deep learning apporte vraiment un gain

### **Phase 4 : CamemBERT Multi-t√¢ches**

**Architecture** :
```
Texte ‚Üí CamemBERT (encodeur partag√©) ‚Üí 3 t√™tes de classification
                                      ‚îú‚îÄ‚Üí T√™te √âmotions (7 classes)
                                      ‚îú‚îÄ‚Üí T√™te Sentiment (3 classes)
                                      ‚îî‚îÄ‚Üí T√™te Ironie (2 classes)
```

**Entra√Ænement** :
- Learning rate : 2e-5 (encodeur) / 1e-4 (t√™tes)
- Batch size : 16 (ou 8 avec gradient accumulation)
- √âpoques : 3-5
- Dropout : 0.3
- Early stopping sur validation F1

**Loss** : Somme pond√©r√©e des 3 t√¢ches
```
Loss_totale = Loss_√©motion + 0.5 √ó Loss_sentiment + 0.3 √ó Loss_ironie
```

### **Phase 5 : √âvaluation**
1. M√©triques : **F1-Score** (macro et weighted), Accuracy, Precision, Recall
2. Matrices de confusion par t√¢che
3. Analyse des erreurs (regarder 50-100 exemples mal class√©s)
4. Visualisations (courbes d'apprentissage, t-SNE des embeddings)

---

## üìà Objectifs de Performance

| T√¢che | M√©trique | Objectif Minimum | Objectif Optimal |
|-------|----------|------------------|------------------|
| √âmotions | F1 (macro) | 0.65 | 0.75+ |
| Sentiment | Accuracy | 0.80 | 0.88+ |
| Ironie | F1 | 0.60 | 0.70+ |

---

## ‚ö° Points Critiques √† Ne Pas Rater

### ‚úÖ √Ä FAIRE ABSOLUMENT

1. **Fixer les seeds** pour la reproductibilit√©
   ```python
   torch.manual_seed(42)
   np.random.seed(42)
   ```

2. **Stratifier** le split train/val/test

3. **Garder les emojis** dans le preprocessing (porteurs d'√©motion !)

4. **Utiliser F1-Score** comme m√©trique principale (pas accuracy)

5. **Faire une baseline simple** avant CamemBERT

6. **Early stopping** pour √©viter l'overfitting

7. **Analyser les erreurs** (pas juste reporter les chiffres)

### ‚ùå √Ä NE PAS FAIRE

1. ‚ùå Pr√©traiter avant de splitter (data leakage)
2. ‚ùå Supprimer les emojis ou la ponctuation excessive
3. ‚ùå Se fier uniquement √† l'accuracy avec classes d√©s√©quilibr√©es
4. ‚ùå Tuner les hyperparam√®tres sur le test set
5. ‚ùå Oublier de documenter l'environnement
6. ‚ùå Ignorer les d√©s√©quilibres de classes

---

## üîß Solutions aux Probl√®mes Courants

### Probl√®me : Classes d√©s√©quilibr√©es
**Solution** : 
- Class weighting dans la loss
- Ou over-sampling (SMOTE)

### Probl√®me : Overfitting
**Solution** :
- Dropout (0.3-0.5)
- Early stopping (patience 2-3 √©poques)
- Data augmentation (back-translation)

### Probl√®me : GPU insuffisant
**Solution** :
- Gradient accumulation (batch effectif = 8 √ó 4 = 32)
- Google Colab gratuit
- R√©duire la longueur max des s√©quences (128 tokens)

### Probl√®me : Ironie difficile √† d√©tecter
**Solution** :
- Utiliser un dataset sp√©cialis√© ironie
- Attention aux emojis (üôÑ, üòè) et ponctuation (!!!, ???)
- C'est normal que ce soit la t√¢che la plus difficile

---

## üìù Livrables Finaux

### 1. Code
- Scripts Python bien document√©s
- Notebooks Jupyter clairs
- README avec instructions

### 2. Mod√®le
- Mod√®le final sauvegard√© (.pt)
- Fichier de config

### 3. Pr√©sentation (15-20 slides)
- Contexte ‚Üí M√©thode ‚Üí R√©sultats ‚Üí Discussion

- Introduction et probl√©matique
- M√©thodologie
- R√©sultats avec tableaux et graphiques
- Analyse d'erreurs
- Discussion et limites
- Conclusion

### 4. D√©mo
- Interface Gradio/Streamlit pour tester le mod√®le

---

## üìÖ Planning Recommand√©

| P√©riode | T√¢ches |
|---------|--------|
| **Jour 1-2** | Setup + collecte donn√©es + exploration |
| **Jour 3** | Preprocessing + statistiques |
| **Jour 4** | Baseline (TF-IDF + ML) |
| **Jour 5-6** | Impl√©mentation CamemBERT multi-t√¢ches |
| **Jour 7-9** | Fine-tuning + optimisation hyperparam√®tres |
| **Jour 10-11** | √âvaluation compl√®te + analyse erreurs |
| **Jour 12-14** | R√©daction rapport |
| **Jour 15** | Pr√©sentation + d√©mo |

---

## üìö Ressources Essentielles

### Datasets
- DEFT 2017 (tweets fran√ßais)
- Allocine (critiques films)
- GoEmotions traduit (√©motions)

### Outils
- Google Colab (GPU gratuit)
- Weights & Biases (tracking exp√©riences)
- Gradio (d√©mo rapide)

---

## Checklist Finale

**Donn√©es** :
- [ ] Corpus collect√© (>5000 exemples)
- [ ] Preprocessing valid√©
- [ ] Split train/val/test stratifi√©

**Mod√®les** :
- [ ] Baseline impl√©ment√©e et √©valu√©e
- [ ] CamemBERT multi-t√¢ches fonctionnel
- [ ] Hyperparam√®tres optimis√©s
- [ ] Objectifs de performance atteints

**√âvaluation** :
- [ ] F1-Score calcul√© pour chaque t√¢che
- [ ] Matrices de confusion g√©n√©r√©es
- [ ] Analyse d'erreurs r√©alis√©e
- [ ] Visualisations cr√©√©es

**Livrables** :
- [ ] Code document√© et test√©
- [ ] Rapport r√©dig√©
- [ ] Pr√©sentation pr√™te
- [ ] D√©mo fonctionnelle (optionnel)

**Rigueur** :
- [ ] Reproductibilit√© garantie
- [ ] Environnement document√©
- [ ] R√©sultats valid√©s
- [ ] Limites discut√©es

---

## En R√©sum√© : Les 3 Choses Essentielles

1. **M√©thodologie rigoureuse** : Baseline ‚Üí Exploration ‚Üí Mod√®le avanc√© ‚Üí Analyse
2. **CamemBERT multi-t√¢ches** : Un encodeur, trois t√™tes de classification
3. **√âvaluation critique** : F1-Score, matrices de confusion, analyse d'erreurs


---
